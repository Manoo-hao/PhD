{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates the 2 remaining files required for input:\n",
    "- True positive genes (nucleotide fasta)\n",
    "- protein alignment (amino acid fasta)\n",
    "IMPORTANTLY, these 2 files are created from non-overlapping sequences!\n",
    "\n",
    "\n",
    "And also moves the corresponding files to new directories so that coverage tables can be generated from them.\n",
    "\n",
    "In the first cell specify:\n",
    "- BGC type (This name must stay constant throughout the scripts)\n",
    "- select_neg_genomes, i.e. the amount of negative genomes to be transferred to the neg_genomes directory\n",
    "- select_neg_genomes, i.e. the amount of positive genomes to be transferred to the pos_genomes directory and to generate the tp_genes file from (the surplus amount will be used to generate the protein alignment from)\n",
    "- pos_isolation_source_filter, if these terms are found in the isolation_source column of the positive samples in the summary file, they will be scored higher in a scoring column, i.e. samples from a known and desired isolation source will be used preferentially.\n",
    "- neg_isolation_source_filter, accordingly\n",
    "- avoid_list. These terms are scored with a 0, end at the bottom of the table, and will be picked last. This is useful when an uncommon gene is searched for and more, and/or more tenuous isolation sources have been allowed during download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGC_type = 'Rieske'\n",
    "select_neg_genomes = 10\n",
    "select_pos_genomes = 3\n",
    "\n",
    "avoid_list = ['', 'isolation_source not annotated']\n",
    "#these are identical to first script, but don't have to be\n",
    "pos_isolation_source_filter =  ['marine', 'sea', 'sponge', 'ocean', 'porifera', 'seafloor','sediment', 'water', 'tidal', 'coral', 'reef', 'coast', 'ship', 'fish', 'aquaculture', 'atlantic', 'pacific', 'mediterranean', 'baltic', 'pond']\n",
    "neg_isolation_source_filter = ['marine', 'sea', 'sponge', 'ocean', 'porifera', 'seafloor', 'sediment', 'water', 'tidal', 'coral', 'reef', 'coast', 'ship', 'fish', 'aquaculture', 'atlantic', 'pacific', 'mediterranean', 'baltic', 'pond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import random\n",
    "import glob\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nesi/project/vuw03285/Rieske/base_genomes/neg_genomes exists already\n",
      "/nesi/project/vuw03285/Rieske/base_genomes/pos_genomes exists already\n"
     ]
    }
   ],
   "source": [
    "def makedir(dirpath):\n",
    "    if os.path.isdir(dirpath):\n",
    "        print(dirpath,'exists already')\n",
    "    else:\n",
    "        print('Making', dirpath)    \n",
    "        os.mkdir(dirpath)\n",
    "\n",
    "        \n",
    "# Defining paths for required directory structure for input and output files relative to parent directory\n",
    "parent_dir='/nesi/project/vuw03285/'\n",
    "BGC_path=os.path.join(parent_dir, BGC_type)\n",
    "neg_genomes_path=os.path.join(BGC_path, 'base_genomes/temp_neg_genomes')\n",
    "pos_genomes_path=os.path.join(BGC_path, 'base_genomes/temp_pos_genomes')\n",
    "output_neg_path=os.path.join(BGC_path, 'base_genomes/neg_genomes')\n",
    "output_pos_path=os.path.join(BGC_path, 'base_genomes/pos_genomes')\n",
    "\n",
    "\n",
    "# Calling function to make directories if they don't exist yet\n",
    "makedir(output_neg_path)\n",
    "makedir(output_pos_path)\n",
    "\n",
    "os.chdir(BGC_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# Generating a report file for this particular script\n",
    "print('\\nBGC_type =', BGC_type)\n",
    "print('\\nselect_neg_genomes =', select_neg_genomes)\n",
    "print('\\nselect_pos_genomes =', select_pos_genomes)\n",
    "print('\\navoid_list =', avoid_list)\n",
    "print('\\nneg_isolation_source_filter =', neg_isolation_source_filter)\n",
    "print('\\npos_isolation_source_filter =', pos_isolation_source_filter, '\\n')\n",
    "with open(BGC_path+'/'+'report_generate_tp.txt', 'w') as f:\n",
    "    f.write(str(cap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load summary table into data frame () output from 1.)\n",
    "summary_file = pd.read_csv('summary.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change order of tables to prioritize samples that have an isolation source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#filter positives and drop all duplicate protein sequences originating from different organisms\n",
    "pos_mask = (summary_file['dir'] == '+')\n",
    "pos_df = summary_file[pos_mask]\n",
    "pos_df.drop_duplicates(subset='protein_id', keep=False, inplace=True)\n",
    "\n",
    "\n",
    "#filter negatives\n",
    "neg_mask = (summary_file['dir'] == '-')\n",
    "neg_df = summary_file[neg_mask]\n",
    "\n",
    "#scoring words in isolation source so as to preferentially pick samples with chosen isolation sources\n",
    "\n",
    "def custom_sorting(source,isolation_source_filter):\n",
    "    score = 1\n",
    "    if isolation_source_filter=='pos':\n",
    "        for word in pos_isolation_source_filter:\n",
    "            if word in source:\n",
    "                score +=1\n",
    "        for word in avoid_list:\n",
    "            if source == word:\n",
    "                score=0\n",
    "    elif isolation_source_filter=='neg':\n",
    "        for word in neg_isolation_source_filter:\n",
    "            if word in source:\n",
    "                score +=1\n",
    "        for word in avoid_list:\n",
    "            if source == word:\n",
    "                score=0\n",
    "    return score\n",
    "\n",
    "\n",
    "pos_df['scoring_column'] = pos_df.apply(lambda x: custom_sorting(x['isolation_source'],'pos'),axis=1)\n",
    "neg_df['scoring_column'] = neg_df.apply(lambda x: custom_sorting(x['isolation_source'],'neg'),axis=1)\n",
    "\n",
    "pos_df.sort_values(by=['scoring_column'], axis=0, ascending=False, inplace=True)\n",
    "neg_df.sort_values(by=['scoring_column'], axis=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moving positive GCF_009363655.1 to /nesi/project/vuw03285/Rieske/base_genomes/pos_genomes\n",
      "moving positive GCF_002116735.1 to /nesi/project/vuw03285/Rieske/base_genomes/pos_genomes\n",
      "moving positive GCF_013459415.1 to /nesi/project/vuw03285/Rieske/base_genomes/pos_genomes\n",
      "generating selected_tp_genes.fasta\n",
      "generating selected_tp_aa.fasta\n",
      "moving negative GCF_000195575.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_011404475.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_002213725.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_002982175.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_013267615.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_005161825.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_003354405.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_001702435.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_005576555.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "moving negative GCF_900478265.1 to /nesi/project/vuw03285/Rieske/base_genomes/neg_genomes\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Split positive genomes into 2 bins, one goes towards tp-genes and is the pos-genomes used for synthesising metagenomes\n",
    "#the other one constitutes a source of protein sequences for alignment as an input file\n",
    "\n",
    "# Genomes selected in such a way that they are from the top of the pre-sorted pos_df\n",
    "unique_pos_df = pos_df.drop_duplicates(subset='assembly', inplace=False)\n",
    "selected_tp_genomes = list(unique_pos_df.iloc[:,1])[0:select_pos_genomes]\n",
    "remaining_pos_genomes = list(unique_pos_df.iloc[:,1])[select_pos_genomes:]\n",
    "\n",
    "#select genomes and isolate GCF number from them, move selected tp genomes to final pos_genomes directory\n",
    "for genome in selected_tp_genomes:\n",
    "    print('moving positive', genome, 'to', output_pos_path)\n",
    "    !mv \"{pos_genomes_path}\"/\"{genome}\"* \"{output_pos_path}\"\n",
    "    \n",
    "#generate dataframe containing all tp-genomes and all the tp-genes contained in it\n",
    "filtered_pos_df = pos_df[pos_df['assembly'].isin(selected_tp_genomes)]\n",
    "remaining_pos_df = pos_df[~pos_df['assembly'].isin(selected_tp_genomes)]\n",
    "\n",
    "#isolate all the headers and transfer them to the selected_tp_genes file\n",
    "full_header_list = []\n",
    "for i in range(0,len(filtered_pos_df)):\n",
    "    full_header=str('>')+filtered_pos_df.iloc[i,1]+str('_')+filtered_pos_df.iloc[i,3]+str('_')+filtered_pos_df.iloc[i,5]\n",
    "    full_header_list.append(full_header)\n",
    "\n",
    "# generate fasta file with selected tp genes found in the selected genomes\n",
    "print('generating selected_tp_genes.fasta')\n",
    "with open(BGC_path+'/'+BGC_type+'_tp_genes.fasta') as fh:\n",
    "    lines=fh.readlines()\n",
    "    for i in range(0,len(lines)):\n",
    "        for j in range(0,len(full_header_list)):\n",
    "            if full_header_list[j] in lines[i]:\n",
    "                with open(BGC_path+'/'+BGC_type+'_selected_tp_genes.fasta', 'a') as outfile:\n",
    "                    outfile.write(lines[i]+lines[i+1])    \n",
    "    \n",
    "# transfer all amino acid sequences that are not part of the tp-genomes to a fasta file\n",
    "print('generating selected_tp_aa.fasta')\n",
    "with open(BGC_path+'/'+BGC_type+'_selected_tp_aa.fasta', 'a') as outfile:\n",
    "    for i in range(0,len(remaining_pos_df)):\n",
    "        fasta_header=str('>')+remaining_pos_df.iloc[i,1]+str('_')+remaining_pos_df.iloc[i,3]+str('_')+remaining_pos_df.iloc[i,5]+'\\n'\n",
    "        sequence = remaining_pos_df.iloc[i,6][2:-2]+'\\n'\n",
    "        outfile.write(fasta_header)\n",
    "        outfile.write(sequence)\n",
    "        \n",
    "        \n",
    "#Move selected neg genome files to different location\n",
    "unique_neg_df = neg_df.drop_duplicates(subset='assembly', inplace=False)\n",
    "selected_neg_genomes = list(unique_neg_df.iloc[:,1])[0:select_neg_genomes]\n",
    "\n",
    "for genome in selected_neg_genomes:\n",
    "    print('moving negative', genome, 'to', output_neg_path)\n",
    "    !mv \"{neg_genomes_path}\"/\"{genome}\"* \"{output_neg_path}\"\n",
    "\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MUSCLE v3.8.1551 by Robert C. Edgar\n",
      "\n",
      "http://www.drive5.com/muscle\n",
      "This software is donated to the public domain.\n",
      "Please cite: Edgar, R.C. Nucleic Acids Res 32(5), 1792-97.\n",
      "\n",
      "Rieske_selected_tp_aa 38 seqs, lengths min 74, max 1122, avg 338\n",
      "00:00:00    19 MB(-2%)  Iter   1  100.00%  K-mer dist pass 1\n",
      "00:00:00    19 MB(-2%)  Iter   1  100.00%  K-mer dist pass 2\n",
      "00:00:00    36 MB(-3%)  Iter   1  100.00%  Align node       \n",
      "00:00:00    36 MB(-3%)  Iter   1  100.00%  Root alignment\n",
      "00:00:01    37 MB(-3%)  Iter   2  100.00%  Refine tree   \n",
      "00:00:01    37 MB(-3%)  Iter   2  100.00%  Root alignment\n",
      "00:00:01    37 MB(-3%)  Iter   2  100.00%  Root alignment\n",
      "00:00:01    37 MB(-3%)  Iter   3  100.00%  Refine biparts\n",
      "00:00:02    37 MB(-3%)  Iter   4  100.00%  Refine biparts\n",
      "00:00:02    37 MB(-3%)  Iter   5  100.00%  Refine biparts\n",
      "00:00:02    37 MB(-3%)  Iter   5  100.00%  Refine biparts\n",
      "00:00:02    37 MB(-3%)  Iter   6  100.00%  Refine biparts\n",
      "00:00:02    37 MB(-3%)  Iter   7  100.00%  Refine biparts\n",
      "00:00:04    37 MB(-3%)  Iter   8  100.00%  Refine biparts\n",
      "00:00:06    37 MB(-3%)  Iter   9  100.00%  Refine biparts\n",
      "00:00:09    37 MB(-3%)  Iter  10  100.00%  Refine biparts\n",
      "00:00:10    37 MB(-3%)  Iter  11  100.00%  Refine biparts\n",
      "00:00:10    37 MB(-3%)  Iter  11  100.00%  Refine biparts\n"
     ]
    }
   ],
   "source": [
    "!module load MUSCLE/3.8.1551\n",
    "#not sure why full path is required?\n",
    "!/opt/nesi/CS400_centos7_bdw/MUSCLE/3.8.1551/bin/muscle -in \"{BGC_path}\"/\"{BGC_type}\"_selected_tp_aa.fasta -out \"{BGC_path}\"/\"{BGC_type}\"_selected_tp_alignment.fasta\n",
    "!module unload MUSCLE/3.8.1551"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 (gimkl-2020a)",
   "language": "python",
   "name": "python382-gimkl-2020a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
