{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar as script 3.0, but the generation of coverage tables, i.e. synthetic metagenomes, is more closely aligned with the Sugimoto 2019 publication. Both dataset1 and dataset2 type synthetic metagenomes can be generated with this script. As it is set up by default, it will generate 70 each of low/high complexity metagenomes.\n",
    "\n",
    "\n",
    "Requires a directory with genomes positive for the selected gene of interest.\n",
    "Requires a directory with genomes negative for the selected gene of interest.\n",
    "\n",
    "The function below generates coverage tables with the following arguments:\n",
    "- complexity: The proportion of negative genomes to include in the synthetic metagenome generated from it relative to the total amount of files in the neg_genomes directory. Needs to be a value between 0 and 1. Eg. for 100 files and a value of 0.1, 10 negative files will be in the synthetic metagenome.\n",
    "- pos_samples: the amount of positive samples to include in the synthetic metagenome. Needs to be a value between 0 and the amount of files in the pos_genomes directory. The for loop calling the function below will generate tables for synthetic metagenomes for all possible values of pos_samples.\n",
    "- amount tables: the amount of coverage tables to generate with the above settings. The for loop calling the function below will generate this amount PER each possible value of pos_samples\n",
    "- logn_mean and logn_std are mean and standard deviation of the normal distribution underlying the lognormal distribution that the coverages are sampled from. The defaults are the values used in sugimoto et al 2019. Both positive and negative genomes are sampled from the same distribution as described for dataset 2 in sugimoto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGC_type = 'RTX_toxin_acyltransferase_combined'\n",
    "metagenome_name = 'RTXtoxinSynSponge' # do not use '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making /media/manu/RiPP_Prioritiser/RTX_toxin_acyltransferase_combined/ds1_coverage_tables\n",
      "Making /media/manu/RiPP_Prioritiser/RTX_toxin_acyltransferase_combined/ds2_coverage_tables\n"
     ]
    }
   ],
   "source": [
    "# Helper function for making directories only if they don't exist yet\n",
    "def makedir(dirpath):\n",
    "    if os.path.isdir(dirpath):\n",
    "        print(dirpath,'exists already')\n",
    "    else:\n",
    "        print('Making', dirpath)    \n",
    "        os.mkdir(dirpath)\n",
    "\n",
    "        \n",
    "# Defining paths for required directory structure for input and output files relative to parent directory\n",
    "#will make directories relative to the path the notebook was opened in\n",
    "parent_dir= !echo $(pwd)\n",
    "BGC_path=os.path.join(parent_dir[0], BGC_type)\n",
    "base_genomes_path=os.path.join(BGC_path, 'base_genomes')\n",
    "neg_genomes_path=os.path.join(BGC_path, 'base_genomes/neg_genomes')\n",
    "pos_genomes_path=os.path.join(BGC_path, 'base_genomes/pos_genomes')\n",
    "ds1_coverage_table_path=os.path.join(BGC_path, 'ds1_coverage_tables')\n",
    "ds2_coverage_table_path=os.path.join(BGC_path, 'ds2_coverage_tables')\n",
    "\n",
    "# made directories manually. comment out or remove after running\n",
    "validation_pos_genomes_path=os.path.join(BGC_path, 'base_genomes/validation_pos_genomes')\n",
    "validation_coverage_table_path=os.path.join(BGC_path, 'validation_coverage_tables')\n",
    "\n",
    "\n",
    "# Calling function to make directories if they don't exist yet\n",
    "makedir(ds1_coverage_table_path)\n",
    "makedir(ds2_coverage_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(BGC_path+'/'+'report_3_generate_coverage_table.txt', 'w') as f:\n",
    "    f.write('Output directory is: '+BGC_path+'\\n')\n",
    "    f.write('\\nBGC_type = '+BGC_type)\n",
    "    f.write('\\nmetagenome_name = '+str(metagenome_name)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg genomes available: 140\n",
      "Pos genomes available: 10\n",
      "Max length of coverage tables is: 150\n"
     ]
    }
   ],
   "source": [
    "# Number depends on the selected pos and neg genomes in previous script\n",
    "# Sugimoto default is 140 neg and 10 pos genomes\n",
    "neg_filenames = [f for f in listdir(neg_genomes_path) if isfile(join(neg_genomes_path, f))]\n",
    "pos_filenames = [f for f in listdir(pos_genomes_path) if isfile(join(pos_genomes_path, f))]\n",
    "#pos_filenames = [f for f in listdir(validation_pos_genomes_path) if isfile(join(validation_pos_genomes_path, f))]\n",
    "\n",
    "all_filenames=neg_filenames+pos_filenames\n",
    "df_len = len(all_filenames)\n",
    "print('Neg genomes available:', len(neg_filenames))\n",
    "print('Pos genomes available:', len(pos_filenames))\n",
    "print('Max length of coverage tables is:', df_len)\n",
    "\n",
    "with open(BGC_path+'/'+'report_3_generate_coverage_table.txt', 'a') as f:\n",
    "    f.write('\\nLength of coverage tables is: '+str(df_len)+'\\n')\n",
    "    f.write('Consisting of: '+str(len(neg_filenames))+' negative genomes and '+str(len(pos_filenames))+' positive genomes.\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite the cell below here according to Sugimoto:\n",
    "\n",
    "Dataset 1:\n",
    "- high complexity metagenomes contain 90% of 140 neg genomes, low complexity metagenomes contain 30% (generate 70 each)\n",
    "- Both high and low complexity metagenomes randomly contain between 0 and 3 positive genomes\n",
    "(- probability that each negative genome is selected is different, probability for each positive genome to be selected is the same.)\n",
    "- proportion of each negative genome is log-normally distributed with mean=1 and variance=4, then normalised so that sum of proportions is 1\n",
    "- Each selected positive genome can have either \"high\" (9-11) or \"low\" (1-4/3) coverage, sampled from a uniform distribution\n",
    "- If a metagenome contains 1 or 3 positive genomes, coverage of each is equally likely to be high or low\n",
    "- If a metagenome contains 2 positive genomes, coverage is high for 1 and low for the other\n",
    "\n",
    "\n",
    "Dataset 2:\n",
    "- Exactly as dataset 1 with the difference that both positive and negative genomes were sampled from a lognormal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function loaded\n"
     ]
    }
   ],
   "source": [
    "#This is for generating datasets required for build input. For validation, use script 3.0\n",
    "def assemble_coverage_tables(complexity, amount_tables, pos_samples=3, logn_mean=1, logn_std=2, dataset=2):\n",
    "\n",
    "    amount_pos_samples = random.randint(0,pos_samples) # Select between 0 and 3 by default\n",
    "    add_samples = round(complexity*len(neg_filenames)) # round to nearest int\n",
    "    \n",
    "    for mg_number in range(0,amount_tables):\n",
    "        \n",
    "        #generate a list of negative coverates of length 'add_samples' and randomly select coverages from it\n",
    "        neg_coverage_list = []\n",
    "        for i in range(0,add_samples):\n",
    "            neg_coverage_list.append(np.random.lognormal(mean=logn_mean, sigma=logn_std))\n",
    "        while len(neg_coverage_list) < len(neg_filenames):\n",
    "            neg_coverage_list.append(0)\n",
    "        randomised_neg_cov = random.sample(neg_coverage_list,len(neg_filenames))\n",
    "\n",
    "        # default - dataset 2, positive and negative samples are selected from same distribution\n",
    "        if dataset == 2:\n",
    "            pos_coverage_list = []\n",
    "            for i in range(0,amount_pos_samples):\n",
    "                pos_coverage_list.append(np.random.lognormal(mean=logn_mean, sigma=logn_std))\n",
    "            while len(pos_coverage_list) < len(pos_filenames):\n",
    "                pos_coverage_list.append(0)\n",
    "            randomised_pos_cov = random.sample(pos_coverage_list,len(pos_filenames))\n",
    "\n",
    "\n",
    "        # dataset 1 - pos samples are chosen from a particular ruleset\n",
    "        elif dataset == 1:\n",
    "            pos_coverage_list = []\n",
    "            #decide if how many pos samples are chosen. Not compatible with non-default pos_samples\n",
    "            rand_pos = random.randint(0,3)\n",
    "            if rand_pos == 0:\n",
    "                pos_coverage_list.append(0)\n",
    "            elif rand_pos == 1:\n",
    "                if random.random() <= 0.5:\n",
    "                    pos_coverage_list.append(random.uniform(9,11))\n",
    "                else:\n",
    "                    pos_coverage_list.append(random.uniform(1,4/3))\n",
    "            elif rand_pos == 2:\n",
    "                pos_coverage_list.append(random.uniform(9,11))\n",
    "                pos_coverage_list.append(random.uniform(1,4/3))\n",
    "            elif rand_pos == 3:\n",
    "                for sample in range(0,rand_pos):\n",
    "                    if random.random() <= 0.5:\n",
    "                        pos_coverage_list.append(random.uniform(9,11))\n",
    "                    else:\n",
    "                        pos_coverage_list.append(random.uniform(1,4/3))\n",
    "            else:\n",
    "                print('dataset 1 not compatible with non-default amount of pos_samples')\n",
    "                return()\n",
    "\n",
    "            while len(pos_coverage_list) < len(pos_filenames):\n",
    "                pos_coverage_list.append(0)\n",
    "            randomised_pos_cov = random.sample(pos_coverage_list,len(pos_filenames))\n",
    "        else:\n",
    "            print('Only 1 and 2 are valid values for dataset')\n",
    "            return()\n",
    "\n",
    "        neg_df_dict = {'metagenome_name':[],'complexity':[],'base_genome_filename':[],'coverage':[]}\n",
    "        for i in range(0,len(neg_filenames)):\n",
    "            neg_df_dict['metagenome_name'].append(metagenome_name+'_'+str(mg_number))\n",
    "            neg_df_dict['complexity'].append(complexity)\n",
    "            neg_df_dict['base_genome_filename'].append(neg_filenames[i])\n",
    "            neg_df_dict['coverage'].append(randomised_neg_cov[i])\n",
    "        neg_cov_df = pd.DataFrame(neg_df_dict)\n",
    "\n",
    "        pos_df_dict = {'metagenome_name':[],'complexity':[],'base_genome_filename':[],'coverage':[]}\n",
    "        for i in range(0,len(pos_filenames)):\n",
    "            pos_df_dict['metagenome_name'].append(metagenome_name+'_'+str(mg_number))\n",
    "            pos_df_dict['complexity'].append(complexity)\n",
    "            pos_df_dict['base_genome_filename'].append(pos_filenames[i])\n",
    "            pos_df_dict['coverage'].append(randomised_pos_cov[i])\n",
    "        pos_cov_df = pd.DataFrame(pos_df_dict)\n",
    "        \n",
    "        \n",
    "        # See plot_mg_correlation notebook to match naming convention! (e.g 0_15_7375_S148.csv)\n",
    "        # Naming must include complexity! Update naming in plot_mg_correlation notebook!\n",
    "        result = pd.concat([neg_cov_df, pos_cov_df])\n",
    "\n",
    "        return(result)\n",
    "\n",
    "print('function loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 2 coverage tables done.\n"
     ]
    }
   ],
   "source": [
    "# dataset 2\n",
    "\n",
    "# Generate coverage tables for 70 low complexity metagenomes\n",
    "\n",
    "metagenome_counter = 0\n",
    "final_amount_tables = 70\n",
    "\n",
    "while metagenome_counter < final_amount_tables:\n",
    "    low_complexity=0.3\n",
    "    result_df = assemble_coverage_tables(complexity=low_complexity, amount_tables=1, dataset=2)\n",
    "    pos_name = len(list(filter(lambda num: num != 0, (result_df.iloc[-len(pos_filenames):,3]))))\n",
    "    neg_name = len(list(filter(lambda num: num != 0, (result_df.iloc[:len(neg_filenames),3]))))\n",
    "    with open(BGC_path+'/'+'report_3_generate_coverage_table.txt', 'a') as f:\n",
    "        f.write(datetime.now(tz=None).strftime('%d/%m/%y, %H:%M:%S')+'\\tGenerating low complexity coverage table '+str(pos_name)+'_'+str(len(pos_filenames)-pos_name)+'_'+str(low_complexity)+'_'+metagenome_name+'_'+str(metagenome_counter)+' with '+str(pos_name)+' positive genome(s) and '+str(neg_name)+' negative genome(s).\\n')\n",
    "    result_df.to_csv(ds2_coverage_table_path+'/'+str(pos_name)+'_'+str(len(pos_filenames)-pos_name)+'_'+str(low_complexity)+'_'+metagenome_name+'_'+str(metagenome_counter), sep=',', index=False, header=False)\n",
    "    metagenome_counter +=1\n",
    "\n",
    "    \n",
    "# Generate coverage tables for 70 high complexity metagenomes\n",
    "\n",
    "metagenome_counter = 0\n",
    "final_amount_tables = 70\n",
    "\n",
    "while metagenome_counter < final_amount_tables:\n",
    "    high_complexity=0.9\n",
    "    result_df = assemble_coverage_tables(complexity=high_complexity, amount_tables=1, dataset=2)\n",
    "    pos_name = len(list(filter(lambda num: num != 0, (result_df.iloc[-len(pos_filenames):,3]))))\n",
    "    neg_name = len(list(filter(lambda num: num != 0, (result_df.iloc[:len(neg_filenames),3]))))\n",
    "    with open(BGC_path+'/'+'report_3_generate_coverage_table.txt', 'a') as f:\n",
    "        f.write(datetime.now(tz=None).strftime('%d/%m/%y, %H:%M:%S')+'\\tGenerating high complexity coverage table '+str(pos_name)+'_'+str(len(pos_filenames)-pos_name)+'_'+str(low_complexity)+'_'+metagenome_name+'_'+str(metagenome_counter)+' with '+str(pos_name)+' positive genome(s) and '+str(neg_name)+' negative genome(s).\\n')\n",
    "    result_df.to_csv(ds2_coverage_table_path+'/'+str(pos_name)+'_'+str(len(pos_filenames)-pos_name)+'_'+str(high_complexity)+'_'+metagenome_name+'_'+str(metagenome_counter), sep=',', index=False, header=False)\n",
    "    metagenome_counter +=1\n",
    "\n",
    "\n",
    "print('Dataset 2 coverage tables done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 coverage tables done.\n"
     ]
    }
   ],
   "source": [
    "# dataset 1\n",
    "\n",
    "# Generate coverage tables for 70 low complexity metagenomes\n",
    "\n",
    "metagenome_counter = 0\n",
    "final_amount_tables = 70\n",
    "\n",
    "while metagenome_counter < final_amount_tables:\n",
    "    low_complexity=0.3\n",
    "    result_df = assemble_coverage_tables(complexity=low_complexity, amount_tables=1, dataset=1)\n",
    "    pos_name = len(list(filter(lambda num: num != 0, (result_df.iloc[-len(pos_filenames):,3]))))\n",
    "    neg_name = len(list(filter(lambda num: num != 0, (result_df.iloc[:len(neg_filenames),3]))))\n",
    "    with open(BGC_path+'/'+'report_3_generate_coverage_table.txt', 'a') as f:\n",
    "        f.write(datetime.now(tz=None).strftime('%d/%m/%y, %H:%M:%S')+'\\tGenerating low complexity coverage table '+str(pos_name)+'_'+str(len(pos_filenames)-pos_name)+'_'+str(low_complexity)+'_'+metagenome_name+'_'+str(metagenome_counter)+' with '+str(pos_name)+' positive genome(s) and '+str(neg_name)+' negative genome(s).\\n')\n",
    "    result_df.to_csv(ds1_coverage_table_path+'/'+str(pos_name)+'_'+str(len(pos_filenames)-pos_name)+'_'+str(low_complexity)+'_'+metagenome_name+'_'+str(metagenome_counter), sep=',', index=False, header=False)\n",
    "    metagenome_counter +=1\n",
    "\n",
    "    \n",
    "# Generate coverage tables for 70 high complexity metagenomes\n",
    "\n",
    "metagenome_counter = 0\n",
    "final_amount_tables = 70\n",
    "\n",
    "while metagenome_counter < final_amount_tables:\n",
    "    high_complexity=0.9\n",
    "    result_df = assemble_coverage_tables(complexity=high_complexity, amount_tables=1, dataset=1)\n",
    "    pos_name = len(list(filter(lambda num: num != 0, (result_df.iloc[-len(pos_filenames):,3]))))\n",
    "    neg_name = len(list(filter(lambda num: num != 0, (result_df.iloc[:len(neg_filenames),3]))))\n",
    "    with open(BGC_path+'/'+'report_3_generate_coverage_table.txt', 'a') as f:\n",
    "        f.write(datetime.now(tz=None).strftime('%d/%m/%y, %H:%M:%S')+'\\tGenerating high complexity coverage table '+str(pos_name)+'_'+str(len(pos_filenames)-pos_name)+'_'+str(low_complexity)+'_'+metagenome_name+'_'+str(metagenome_counter)+' with '+str(pos_name)+' positive genome(s) and '+str(neg_name)+' negative genome(s).\\n')\n",
    "    result_df.to_csv(ds1_coverage_table_path+'/'+str(pos_name)+'_'+str(len(pos_filenames)-pos_name)+'_'+str(high_complexity)+'_'+metagenome_name+'_'+str(metagenome_counter), sep=',', index=False, header=False)\n",
    "    metagenome_counter +=1\n",
    "\n",
    "\n",
    "print('Dataset 1 coverage tables done.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
